{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Simulated Lenses in DESI using Visual Transformer\n",
    "\n",
    "Author: Anthony LaBarca, modified by Delaney Cummins\n",
    "\n",
    "Date: 2023-07-24\n",
    "\n",
    "Version: 1.0\n",
    "\n",
    "License: ---\n",
    "\n",
    "Description: This script will adapt the ViT model to DESI spectral data of resolution 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchsummary\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "def is_interactive():\n",
    "    import __main__ as main\n",
    "    return not hasattr(main, \"__file__\")\n",
    "\n",
    "\n",
    "if is_interactive():\n",
    "    from tqdm.notebook import tqdm, trange\n",
    "else:\n",
    "    from tqdm import tqdm, trange\n",
    "\n",
    "# Imports\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Synthetic Data Location \n",
    "#filepath to pickles\n",
    "# filepath='/global/homes/a/alabarca/DESI-Timedomain/simulated_preprocessing/old/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ViT Code (Don't want to deal with any imports atm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "EXAMPLE OUTPUT OF TRANFORMER WITH 100 PATCHES\n",
    "torch.Size([1, 100, 36])                                                                 # Original \n",
    "torch.Size([1, 100, 25])                                                                 # Move to hidden Dimension\n",
    "torch.Size([1, 101, 25])                                                                 # Add Classification Token\n",
    "torch.Size([1, 101, 25])                                                                 # Add positional embeddings\n",
    "torch.Size([1, 101, 25])                                                                 # 1 ViT Block\n",
    "torch.Size([1, 101, 25])                                                                 # 2 ViT Block\n",
    "torch.Size([1, 101, 25])                                                                 # 3 Vit Block\n",
    "torch.Size([1, 101, 25])                                                                 # 4 ViT Block\n",
    "torch.Size([1, 101, 25])                                                                 # 5 ViT Block\n",
    "torch.Size([1, 25])                                                                      # Take only the classification Token\n",
    "tensor([[0.4370, 0.1115, 0.0393, 0.0505, 0.0449, 0.3168]], grad_fn=<SoftmaxBackward>)    # Final Output (Predictions)\n",
    "'''\n",
    "''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ViT Training\n",
      "--------------------\n",
      "DEVICE IN USE cpu\n",
      "Model name:  vit_model_V1_big\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing ViT Training\")\n",
    "print(\"-\"* 20)\n",
    "batch_size=256\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"DEVICE IN USE {device}\")\n",
    "\n",
    "num_epochs= 60\n",
    "learning_rate=0.001\n",
    "model_suff='lens-3600'\n",
    "plot=False\n",
    "retrain = True\n",
    "continue_train = True\n",
    "previous_epoch = 0\n",
    "\n",
    " # model_name\n",
    "model_name = f\"vit_model_{model_suff}\"\n",
    "print(\"Model name: \", model_name)\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data and turn into dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:  torch.Size([15514, 1, 7800])\n",
      "Test set:  torch.Size([5172, 1, 7800])\n"
     ]
    }
   ],
   "source": [
    "# Load parameters and data\n",
    "with open(f\"split/parameters.json\", \"r\") as f:\n",
    "    model_params = json.load(f)\n",
    "\n",
    "patch_size = model_params['patch_size']\n",
    "patch_num = model_params['patch_num']\n",
    "spectra_length = model_params['spectra_length']\n",
    "\n",
    "x_train = torch.Tensor(np.load('split/V1_xtrain.npy'))\n",
    "y_train = torch.Tensor(np.load('split/V1_ytrain.npy')).long().squeeze()\n",
    "x_test = torch.Tensor(np.load('split/V1_xtest.npy'))\n",
    "y_test = torch.Tensor(np.load('split/V1_ytest.npy')).long().squeeze()\n",
    "\n",
    "print(\"Training set: \", x_train.shape)\n",
    "print(\"Test set: \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "def get_dataloaders(x_train, x_test, y_train, y_test, batch_size, device):\n",
    "    class SpectraDataset(Dataset):\n",
    "        def __init__(self, x, y):\n",
    "            self.x = x\n",
    "            self.y = y\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.x)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            return self.x[idx], self.y[idx]\n",
    "    \n",
    "    train_dataset = SpectraDataset(x_train, y_train)\n",
    "    test_dataset = SpectraDataset(x_test, y_test)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=device)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=device)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "\n",
    "train_loader, test_loader = get_dataloaders(x_train, x_test, y_train, y_test, batch_size, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Methods\n",
    "def patchify(spectra: torch.Tensor, n_patches: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    spectra: 1D spectra: torch.Tensor of shape (N, 1, len_spectrum)\n",
    "    n_patches: number of patches to break the spectra into (must be a factor of len_spectrum)\n",
    "\n",
    "    return: patches of the spectra: torch.Tensor of shape (N, n_patches, len_spectrum // n_patches)\n",
    "    \"\"\"\n",
    "\n",
    "    n, _, l_spectrum = spectra.shape\n",
    "\n",
    "    # create patches\n",
    "    patch_size = l_spectrum // n_patches\n",
    "    patches = torch.zeros(n, n_patches, l_spectrum // n_patches)\n",
    "    for idx, spectrum in enumerate(spectra):\n",
    "        for i in range(n_patches):\n",
    "            patch = spectrum[:, i * patch_size: (i + 1) * patch_size]\n",
    "            patches[idx, i] = patch\n",
    "\n",
    "    return patches\n",
    "\n",
    "def positional_embedding(i, j, d):\n",
    "    \"\"\"\n",
    "    i: tensor index\n",
    "    j: embedding dimension\n",
    "\n",
    "    return: positional embedding for i, j\n",
    "    \"\"\"\n",
    "\n",
    "    if j % 2 == 0:\n",
    "        return np.sin(i / (10000 ** (j / d)))\n",
    "    return np.cos(i / (10000 ** ((j - 1) / d)))\n",
    "\n",
    "\n",
    "def get_positional_embeddings(sequence_length: int, d) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    sequence_length: length of sequence\n",
    "    d: embedding dimension\n",
    "\n",
    "    return: positional embeddings for sequence of length sequence_length\n",
    "    \"\"\"\n",
    "\n",
    "    result = torch.ones(sequence_length, d)\n",
    "    for i in range(sequence_length):\n",
    "        for j in range(d):\n",
    "            result[i][j] = positional_embedding(i, j, d)\n",
    "\n",
    "    return result\n",
    "    \n",
    "class MSA(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Head Self-Attention\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d, n_heads=2):\n",
    "        super(MSA, self).__init__()\n",
    "        self.d = d\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        assert d % n_heads == 0, f\"Cannot divide dimension {d} into {n_heads} heads\"\n",
    "        \n",
    "        d_head = int(d / n_heads)\n",
    "        self.q_mappings = nn.ModuleList(\n",
    "            [nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
    "        self.k_mappings = nn.ModuleList(\n",
    "            [nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
    "        self.v_mappings = nn.ModuleList(\n",
    "            [nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
    "        self.d_head = d_head\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self, sequences):\n",
    "        \"\"\"\n",
    "        Sequences have shapes (N, seq_length, token_dim)\n",
    "        We must transform to shape (N, seq_length, n_heads, token_dim / n_heads)\n",
    "        and concatenate back into (N, seq_length, token_dim)\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        for sequence in sequences:\n",
    "            seq_result = []\n",
    "            for head in range(self.n_heads):\n",
    "                q_mapping = self.q_mappings[head]\n",
    "                k_mapping = self.k_mappings[head]\n",
    "                v_mapping = self.v_mappings[head]\n",
    "                \n",
    "                seq = sequence[:, head * self.d_head: (head + 1) * self.d_head]\n",
    "                q, k, v = q_mapping(seq), k_mapping(seq), v_mapping(seq)\n",
    "                \n",
    "                attention = self.softmax(q @ k.T / (self.d_head ** 0.5))\n",
    "                seq_result.append(attention @ v)\n",
    "            result.append(torch.hstack(seq_result))\n",
    "        return torch.cat([torch.unsqueeze(r, dim=0) for r in result])\n",
    "\n",
    "\n",
    "class ViTBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer Encoder Block\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_d, n_heads, mlp_ratio=4):\n",
    "        super(ViTBlock, self).__init__()\n",
    "        self.hidden_d = hidden_d\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(hidden_d)\n",
    "        self.mhsa = MSA(hidden_d, n_heads)\n",
    "        self.norm2 = nn.LayerNorm(hidden_d)\n",
    "        self.mlp = nn.Sequential(nn.Linear(hidden_d, mlp_ratio * hidden_d), nn.GELU(),\n",
    "                                 nn.Linear(mlp_ratio * hidden_d, hidden_d))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Encoder1 will normalize input, pass through MSA,\n",
    "        add residual connection\n",
    "\n",
    "        Encoder2 will normalize encoder1, pass through MLP\n",
    "        \"\"\"\n",
    "        encoder1 = x + self.mhsa(self.norm1(x))\n",
    "        encoder2 = encoder1 + self.mlp(self.norm2(encoder1))\n",
    "        return encoder2\n",
    "\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, cl=(1, 1024), n_patches=64, n_blocks=2, hidden_d=8, n_heads=2, out_d=10, device = None):\n",
    "        super(ViT, self).__init__()\n",
    "        \n",
    "        # If device is provided, use that. \n",
    "        # HOwever, if CUDA is availible, that is the default device\n",
    "        if device is not None:\n",
    "            self.device = device\n",
    "        else:\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"ViT IS NOW IN {self.device}\")\n",
    "        \n",
    "        self.cl = cl  # (channels, length)\n",
    "        self.n_patches = n_patches\n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_heads = n_heads\n",
    "        self.hidden_d = hidden_d\n",
    "        \n",
    "        assert cl[1] % n_patches == 0, \"Image length must be divisible by n_patches\"\n",
    "        self.patch_size = cl[1] // n_patches\n",
    "        \n",
    "        # Linear mapping of patches to hidden dimension\n",
    "        self.input_d = int(cl[0] * self.patch_size)\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.hidden_d).to(self.device)\n",
    "        \n",
    "        # Classification Token\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.hidden_d).to(self.device))\n",
    "        \n",
    "        # Positional embeddings\n",
    "        self.pos_embed = nn.Parameter(get_positional_embeddings(\n",
    "            n_patches + 1, self.hidden_d).clone().detach())\n",
    "        self.pos_embed.requires_grad = False\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [ViTBlock(hidden_d, n_heads) for _ in range(n_blocks)]).to(self.device)\n",
    "        \n",
    "        # Classification mlp\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(self.hidden_d, out_d), nn.Softmax(dim=-1)).to(self.device)\n",
    "        \n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=1.0)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    \n",
    "    def forward(self, images):\n",
    "        # Creating patches\n",
    "        n, _, _ = images.shape\n",
    "        patches = patchify(images, self.n_patches).to(self.device)\n",
    "        # Linear tokenization --> map vector corresponding to each patch to hidden dimension\n",
    "        image_tokens = self.linear_mapper(patches)\n",
    "        # Adding classification\n",
    "        tokens = torch.stack([torch.vstack(\n",
    "            (self.class_token, image_tokens[i])) for i in range(len(image_tokens))])\n",
    "        # Adding positional embeddings\n",
    "        pos_embed = self.pos_embed.repeat(n, 1, 1)\n",
    "        out = tokens + pos_embed\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            out = block(out)\n",
    "        \n",
    "        # For classification, we take the first token\n",
    "        out = out[:, 0]\n",
    "        \n",
    "        return self.mlp(out)\n",
    "    \n",
    "    def saveparams(self, model_name):\n",
    "        dict = {'cl': self.cl, 'patches':self.n_patches, 'n_blocks':self.n_blocks, 'n_heads':self.n_heads, 'hidden_d':self.hidden_d}\n",
    "        with open(f'{model_name}_parameters.json', 'w') as f:\n",
    "            json.dump(dict, f)\n",
    "\n",
    "# Create Old Model \n",
    "# model = ViT(cl=(1, spectra_length), n_patches=patch_num, n_blocks=4, hidden_d = patch_num // 4, n_heads = 5, out_d = 6).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT IS NOW IN cpu\n"
     ]
    }
   ],
   "source": [
    "# Create New Model\n",
    "model = ViT(cl=(1, spectra_length), n_patches=patch_num, n_blocks=4, hidden_d = patch_size * 2, n_heads = 12, out_d = 2).to(device)\n",
    "\n",
    "model.saveparams(model_name)\n",
    "\n",
    "\n",
    "\n",
    "# Optimizer and Loss Functions\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Initialize History Tracking\n",
    "model_history = {}\n",
    "# if continue_train and previous_epoch > 0:\n",
    "#     with open(f'{model_name}_history.json', \"r\") as f:\n",
    "#         model_history = json.load(f)\n",
    "#         print(\"Loaded\")\n",
    "#     model.load_state_dict(torch.load(f'model/{model_name}_epoch{previous_epoch}.pt'))\n",
    "#     print(\"Loaded\")\n",
    "\n",
    "#torchsummary.summary(model, (1, spectra_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, model, device, epoch, criterion, optimizer):\n",
    "    train_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n",
    "        x, y = batch\n",
    "        x = x.type(torch.LongTensor) \n",
    "        y = y.type(torch.LongTensor) \n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        \n",
    "        train_loss += loss.detach().cpu().item() / len(train_loader)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return train_loss\n",
    "\n",
    "def test_model(test_loader: DataLoader, model: nn.Module, device: torch.device, criterion, plot: bool = True):\n",
    "    \"\"\"\n",
    "    Test the model on the test set \n",
    "\n",
    "    Parameters: \n",
    "    -----------\n",
    "    test_loader: DataLoader \n",
    "    \"\"\"\n",
    "    model.train().to(device)\n",
    "    \n",
    "    correct, total = 0, 0\n",
    "    test_loss = 0.0\n",
    "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "        x, y = batch\n",
    "        x = x.type(torch.LongTensor) \n",
    "        y = y.type(torch.LongTensor) \n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        # force printout\n",
    "        loss = criterion(y_hat, y)\n",
    "        test_loss += loss.detach().cpu().item() / len(test_loader)\n",
    "        \n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1)\n",
    "                             == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "    print(f\"Test loss: {test_loss:.2f}\")\n",
    "    print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "\n",
    "    # If you don't want Predictions, just return and get out \n",
    "    # if plot or y_hat is None:\n",
    "    return correct / total * 100, test_loss\n",
    "    \n",
    "#     # If you want a figure, make some predictions\n",
    "#     # get first batch from dataset, and plot the first 10 predictions made by the model\n",
    "#     data = next(iter(test_loader))\n",
    "#     x, y = data\n",
    "#     x = x.type(torch.LongTensor) \n",
    "#     y = y.type(torch.LongTensor) \n",
    "#     x, y = x.to(device), y.to(device)\n",
    "#     y_hat = model(x)\n",
    "\n",
    "#     fig, ax = plt.subplots(10, 1, figsize=(10, 20), sharex=\"all\")\n",
    "#     for i in range(10):\n",
    "#         print(f\"Prediction: {torch.argmax(y_hat[i])}, Label: {y[i]}\")\n",
    "#         ax[i].plot(x[i][0])\n",
    "#         ax[i].set_title(\n",
    "#             f\"Prediction: {torch.argmax(y_hat[i])}, Label: {y[i]}\")\n",
    "#     fig.supylabel(\"Intensity\")\n",
    "#     fig.supxlabel(\"Wavelength\")\n",
    "#     fig.tight_layout()\n",
    "#     return correct / total * 100, test_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20be028b736e49dba0c18e0a0471553e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c859a7dc694f518b4f839716d76969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 in training:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 loss: 0.85\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a72cd906d87a4e46ba294bdcda648d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.84\n",
      "Test accuracy: 46.95%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801ddc0d52784ef3bb73d84fde3e2f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 in training:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 loss: 0.85\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eacaa7e17fa4a49b5dfa8722f38eecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.84\n",
      "Test accuracy: 46.95%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9cd206912f41d0a3dff3a205601ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 in training:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 loss: 0.86\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b589358589934611a63a306c66a5ea0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.84\n",
      "Test accuracy: 46.95%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6652376989f542459d37f7ca7704b5b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 in training:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 loss: 0.86\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2c8f2acd9b4832b90698b7760ce5af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.84\n",
      "Test accuracy: 46.95%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292322ea81a84b84a5d75119aba76bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 in training:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 loss: 0.85\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdbe734d5dc1490480d6596ce915c1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.84\n",
      "Test accuracy: 46.95%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "481fe5e395f84f56b94df1e5440dd14d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 in training:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 loss: 0.86\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c2c36e5e2a45eb86c9e47babdd8ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.84\n",
      "Test accuracy: 46.95%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6af15cc867445bf8e896a34ef34fdf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 in training:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 loss: 0.86\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c153fbbee34ba8b37a0f02c7c2954f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.84\n",
      "Test accuracy: 46.95%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25330f239e14b6090f4cec0ac315c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 in training:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 loss: 0.86\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36bf834d28e64323818deeaf36439ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.84\n",
      "Test accuracy: 46.95%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f9454de9664acdb956ecacdc5cd18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 in training:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 loss: 0.86\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813d288b6603478a851b1d236bdf105e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.84\n",
      "Test accuracy: 46.95%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5762ef7cc6354313a0d4917184c9808a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 in training:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/local_scratch/17117086/ipykernel_4180/3515924322.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {previous_epoch + epoch + 1}/{previous_epoch + num_epochs} loss: {train_loss:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local_scratch/17117086/ipykernel_4180/2924489333.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_loader, model, device, epoch, criterion, optimizer)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/miniconda3/4.9.2/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/software/miniconda3/4.9.2/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not os.path.exists(model_name) or retrain:\n",
    "    training_loss, test_loss, test_acc = [], [], []\n",
    "    if continue_train and previous_epoch > 0:\n",
    "        training_loss = model_history[\"training_loss\"]\n",
    "        test_loss = model_history[\"test_loss\"]\n",
    "        test_acc = model_history[\"test_acc\"]\n",
    "    print(len(training_loss))\n",
    "    # Training loop\n",
    "    for epoch in trange(num_epochs, desc=\"Training\"):\n",
    "        # Train model\n",
    "        model.train().to(device)\n",
    "\n",
    "        train_loss = train_model(train_loader, model, device, epoch, criterion, optimizer)\n",
    "        print(f\"Epoch {previous_epoch + epoch + 1}/{previous_epoch + num_epochs} loss: {train_loss:.2f}\")\n",
    "\n",
    "        # Test model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_acc_curr, test_loss_curr = test_model(test_loader, model, device, criterion, plot=False)\n",
    "\n",
    "        # Bookkeeping\n",
    "        training_loss.append(train_loss)\n",
    "        test_loss.append(test_loss_curr)\n",
    "        test_acc.append(test_acc_curr)\n",
    "        # Save model\n",
    "        model_history = {\"training_loss\": training_loss, \"test_loss\": test_loss, \"test_acc\": test_acc}\n",
    "        # Save model and history\n",
    "        torch.save(model.state_dict(), f\"model/{model_name}_epoch{previous_epoch + epoch}.pt\")\n",
    "        \n",
    "        with open(f\"{model_name}_history.json\", \"w\") as f:\n",
    "            json.dump(model_history, f)\n",
    "\n",
    "    if plot:\n",
    "        with torch.no_grad():\n",
    "            test_model(test_loader, model, device, criterion, plot=plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history: dict, figure=None):\n",
    "    \"\"\"\n",
    "    Plot training history\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    history: dict\n",
    "        Dictionary with training history\n",
    "    figure: tuple\n",
    "        Tuple of (fig, ax) to plot on\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig, ax\n",
    "        Figure and axis\n",
    "    \"\"\"\n",
    "    # plot on one axis, with two y axes (one for loss, one for accuracy)\n",
    "    \n",
    "    # figure is either None, or a tuple of (fig, ax)\n",
    "    if figure is None:\n",
    "        fig, ax1 = plt.subplots(1, 1, figsize=(10, 5))\n",
    "        assert isinstance(ax1, plt.Axes), \"Figure must be a tuple of (fig, ax)\"\n",
    "        ax2 = ax1.twinx()\n",
    "    else:\n",
    "        fig, ax = tuple(figure)\n",
    "        if isinstance(ax, np.ndarray):\n",
    "            ax1 = ax[0]\n",
    "            ax2 = ax[1]\n",
    "        else:\n",
    "            assert isinstance(\n",
    "                ax, plt.Axes), \"Figure must be a tuple of (fig, ax)\"\n",
    "            ax1 = ax\n",
    "            ax2 = ax1.twinx()\n",
    "    \n",
    "    assert isinstance(ax1, plt.Axes), \"Figure must be a tuple of (fig, ax)\"\n",
    "    assert isinstance(ax2, plt.Axes), \"Figure must be a tuple of (fig, ax)\"\n",
    "    \n",
    "    # List of colors to be used\n",
    "    colors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\",\n",
    "              \"tab:brown\", \"tab:pink\", \"tab:gray\", \"tab:olive\", \"tab:cyan\"]\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.plot(history[\"training_loss\"], label=\"Training loss\", color=colors[0])\n",
    "    ax1.plot(history[\"test_loss\"], label=\"Test loss\", color=colors[1])\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    # Use the 3rd color in the color cycle\n",
    "    ax2.plot(history[\"test_acc\"], label=\"Test accuracy\", color=colors[2])\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    ax2.legend()\n",
    "    ax = (ax1, ax2)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "print(type(ax))\n",
    "history_figure2, hist_ax = plot_history(model_history, figure = (fig, ax))\n",
    "history_figure2.suptitle(\"Loss and Accuracy of ViT\")\n",
    "history_figure2.tight_layout()\n",
    "history_figure2.savefig(f'history-{model_name}.png', facecolor='white', transparent=False, edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positional_embeddings(sequence_length: int, d) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    sequence_length: length of sequence\n",
    "    d: embedding dimension\n",
    "\n",
    "    return: positional embeddings for sequence of length sequence_length\n",
    "    \"\"\"\n",
    "    \n",
    "    result = torch.ones(sequence_length, d)\n",
    "    for i in range(sequence_length):\n",
    "        for j in range(d):\n",
    "            result[i][j] = positional_embedding(i, j, d)\n",
    "    \n",
    "    return result\n",
    "\n",
    "test = nn.Parameter(get_positional_embeddings(100 + 1, 300).clone().detach())\n",
    "\n",
    "pos_embed = test.repeat(1, 1, 1)\n",
    "fig, ax = plt.subplots(1,1, figsize=(4,4))\n",
    "print(pos_embed[0].detach().numpy().shape)\n",
    "ax.imshow(pos_embed[0].detach().numpy())\n",
    "ax.set_title(\"Positional Embeddings\")\n",
    "ax.set_xlabel(\"Hidden Dimension\")\n",
    "ax.set_ylabel(\"Patch #\")\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"embeddings.png\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.9.1)",
   "language": "python",
   "name": "pytorch-1.9.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
